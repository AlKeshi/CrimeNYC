{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, layers, Model\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NYC shapefile...\n",
      "Creating mask from NYC boundaries...\n",
      "Mask created: 1886.0 cells inside NYC out of 3350 total\n"
     ]
    }
   ],
   "source": [
    "# Load NYC borough shapefile\n",
    "print(\"Loading NYC shapefile...\")\n",
    "path = '../data/shapefile/nyc_boroughs.shp'\n",
    "nyc = gpd.read_file(path)\n",
    "# Transform to WGS84 (EPSG:4326) to match crime data coordinates\n",
    "nyc = nyc.to_crs(\"EPSG:4326\")\n",
    "nyc = nyc.dissolve()\n",
    "\n",
    "# Load data to get dimensions\n",
    "train_data_temp = np.load('../data/train_data.npy')\n",
    "n_y_cells, n_x_cells = train_data_temp.shape[1], train_data_temp.shape[2]\n",
    "\n",
    "# Create mask using shapefile bounds (like Chicago version)\n",
    "print(\"Creating mask from NYC boundaries...\")\n",
    "xmin, ymin, xmax, ymax = nyc.total_bounds\n",
    "x_cell_size = (xmax - xmin) / n_x_cells\n",
    "y_cell_size = (ymax - ymin) / n_y_cells\n",
    "mask = np.ones((n_y_cells, n_x_cells))\n",
    "nyc_geom = nyc.geometry.values[0]\n",
    "\n",
    "x_arange = np.arange(xmin, xmax+x_cell_size, x_cell_size)\n",
    "y_arange = np.arange(ymin, ymax+y_cell_size, y_cell_size)\n",
    "for i, y0 in zip(range(n_y_cells-1, -1, -1), y_arange):\n",
    "    for j, x0 in zip(range(n_x_cells), x_arange):\n",
    "        x1 = x0 + x_cell_size\n",
    "        y1 = y0 + y_cell_size\n",
    "        box = shapely.geometry.box(x0, y0, x1, y1)\n",
    "        if not nyc_geom.intersects(box):\n",
    "            mask[i,j] = 0\n",
    "\n",
    "print(f\"Mask created: {np.sum(mask)} cells inside NYC out of {n_y_cells * n_x_cells} total\")\n",
    "\n",
    "# Convert mask for TensorFlow\n",
    "mask = tf.keras.backend.constant(mask)\n",
    "mask = tf.expand_dims(mask, -1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training 4 Hetero-ConvLSTMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fradi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3809s\u001b[0m 10s/step - loss: 0.7413 - mae: 0.3997\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 3s/step\n"
     ]
    }
   ],
   "source": [
    "lookback = 7\n",
    "batch_size = 4\n",
    "\n",
    "train_X_crimes_only = np.load('../data/train_data.npy')\n",
    "test_X_crimes_only = np.load('../data/test_data.npy')\n",
    "\n",
    "train_X_crimes_only = tf.expand_dims(train_X_crimes_only, -1)\n",
    "test_X_crimes_only = tf.expand_dims(test_X_crimes_only, -1)\n",
    "\n",
    "train_gen = TimeseriesGenerator(\n",
    "    train_X_crimes_only,\n",
    "    train_X_crimes_only,\n",
    "    length=lookback,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "test_gen = TimeseriesGenerator(\n",
    "    test_X_crimes_only,\n",
    "    test_X_crimes_only,\n",
    "    length=lookback,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "def masked_MSE_loss(y_true, y_pred):\n",
    "    y_pred_masked = tf.math.multiply(y_pred, mask)\n",
    "    # Use reduce_mean instead of deprecated mean_squared_error\n",
    "    mse = tf.reduce_mean(tf.square(y_true - y_pred_masked))\n",
    "    return mse\n",
    "\n",
    "# Define the input tensors\n",
    "inputs = Input(shape=(lookback, *train_X_crimes_only.shape[1:]))\n",
    "\n",
    "# First stack of convlstm layers\n",
    "convlstm1 = layers.ConvLSTM2D(filters=128, kernel_size=(3, 3), padding='same', activation='tanh', return_sequences=True)(inputs)\n",
    "bathnorm1 = layers.BatchNormalization()(convlstm1)\n",
    "convlstm2 = layers.ConvLSTM2D(filters=128, kernel_size=(3, 3), padding='same', activation='tanh', return_sequences=False)(bathnorm1)\n",
    "\n",
    "# Second stack of convlstm layers\n",
    "convlstm3 = layers.ConvLSTM2D(filters=128, kernel_size=(3, 3), padding='same', activation='tanh', return_sequences=True)(inputs)\n",
    "batchnorm2 = layers.BatchNormalization()(convlstm3)\n",
    "convlstm4 = layers.ConvLSTM2D(filters=128, kernel_size=(3, 3), padding='same', activation='tanh', return_sequences=False)(batchnorm2)\n",
    "\n",
    "# Concatenate outputs of two stacks\n",
    "concatenation = layers.concatenate([convlstm2, convlstm4])\n",
    "outputs = layers.Conv2D(filters=1, kernel_size=1, padding=\"same\", activation='linear')(concatenation)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss=masked_MSE_loss, metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_gen, epochs=1)\n",
    "\n",
    "# Create test prediction\n",
    "test_pred = model.predict(test_gen)\n",
    "test_pred *= mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/homo_convlstm.npy', test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
